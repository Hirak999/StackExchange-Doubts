{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import *\n",
    "from matplotlib import *\n",
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "var=read_csv(r\"C:\\Users\\Hirak\\Desktop\\Machine Learning A-Z\\Part 2 - Regression\\Section 5 - Multiple Linear Regression\\50_Startups.csv\")\n",
    "var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\anacode\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "M:\\anacode\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#now we will split the data into train set and test set\n",
    "\n",
    "X=var.iloc[:, :-1].values  \n",
    "Y=var.iloc[:,4:5].values\n",
    "\n",
    "#now see that state is a categorical variable, so we need to Label Encode them first and then One Hot Encode it\n",
    "\n",
    "# 1. Label encodiing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_X=LabelEncoder() \n",
    "    \n",
    "X[:,3]=le_X.fit_transform(X[:,3]) \n",
    "\n",
    "\n",
    "# 2.Dummy variable i.e. One Hot Encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "OHE_object=OneHotEncoder(categorical_features = [3]) #[0] refers to the column which we want to OneHotEncode\n",
    "\n",
    "X=OHE_object.fit_transform(X).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0      1 165349 136897 471784]\n",
      " [     1      0      0 162597 151377 443898]\n",
      " [     0      1      0 153441 101145 407934]\n",
      " [     0      0      1 144372 118671 383199]\n",
      " [     0      1      0 142107  91391 366168]\n",
      " [     0      0      1 131876  99814 362861]\n",
      " [     1      0      0 134615 147198 127716]\n",
      " [     0      1      0 130298 145530 323876]\n",
      " [     0      0      1 120542 148718 311613]\n",
      " [     1      0      0 123334 108679 304981]\n",
      " [     0      1      0 101913 110594 229160]\n",
      " [     1      0      0 100671  91790 249744]\n",
      " [     0      1      0  93863 127320 249839]\n",
      " [     1      0      0  91992 135495 252664]\n",
      " [     0      1      0 119943 156547 256512]\n",
      " [     0      0      1 114523 122616 261776]\n",
      " [     1      0      0  78013 121597 264346]\n",
      " [     0      0      1  94657 145077 282574]\n",
      " [     0      1      0  91749 114175 294919]\n",
      " [     0      0      1  86419 153514      0]\n",
      " [     1      0      0  76253 113867 298664]\n",
      " [     0      0      1  78389 153773 299737]\n",
      " [     0      1      0  73994 122782 303319]\n",
      " [     0      1      0  67532 105751 304768]\n",
      " [     0      0      1  77044  99281 140574]\n",
      " [     1      0      0  64664 139553 137962]\n",
      " [     0      1      0  75328 144135 134050]\n",
      " [     0      0      1  72107 127864 353183]\n",
      " [     0      1      0  66051 182645 118148]\n",
      " [     0      0      1  65605 153032 107138]\n",
      " [     0      1      0  61994 115641  91131]\n",
      " [     0      0      1  61136 152701  88218]\n",
      " [     1      0      0  63408 129219  46085]\n",
      " [     0      1      0  55493 103057 214634]\n",
      " [     1      0      0  46426 157693 210797]\n",
      " [     0      0      1  46014  85047 205517]\n",
      " [     0      1      0  28663 127056 201126]\n",
      " [     1      0      0  44069  51283 197029]\n",
      " [     0      0      1  20229  65947 185265]\n",
      " [     1      0      0  38558  82982 174999]\n",
      " [     1      0      0  28754 118546 172795]\n",
      " [     0      1      0  27892  84710 164470]\n",
      " [     1      0      0  23640  96189 148001]\n",
      " [     0      0      1  15505 127382  35534]\n",
      " [     1      0      0  22177 154806  28334]\n",
      " [     0      0      1   1000 124153   1903]\n",
      " [     0      1      0   1315 115816 297114]\n",
      " [     1      0      0      0 135426      0]\n",
      " [     0      0      1    542  51743      0]\n",
      " [     1      0      0      0 116983  45173]]\n"
     ]
    }
   ],
   "source": [
    "print(X.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# though Linear Regression library has inbuilt DUmmy Variable trap removal feature, but we will still learn it since\n",
    "# there are some libraries where we have to do it manually.\n",
    "\n",
    "\n",
    "# X=X[:,1:] #this means take all rows and all columns starting from index 1\n",
    "\n",
    "# print(X.astype(int)) #see that we have removed the first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will do the train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train,X_test,Y_train,Y_test= tts (X,Y,test_size=0.2,random_state=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81649658,  1.73205081, -0.73379939, -0.35006454, -0.78547109,\n",
       "         0.1011968 ],\n",
       "       [-0.81649658, -0.57735027,  1.36277029, -0.55530319, -1.48117426,\n",
       "         0.02734979],\n",
       "       [-0.81649658,  1.73205081, -0.73379939,  0.07935762,  0.80133381,\n",
       "        -0.55152132],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -0.54638238,  1.32505817,\n",
       "         0.07011684],\n",
       "       [-0.81649658,  1.73205081, -0.73379939,  0.43485371, -0.35598663,\n",
       "         0.75148516],\n",
       "       [-0.81649658,  1.73205081, -0.73379939,  1.26943143,  0.85518519,\n",
       "         0.98603118],\n",
       "       [-0.81649658,  1.73205081, -0.73379939,  1.04525007,  1.28077047,\n",
       "         0.4404    ],\n",
       "       [-0.81649658, -0.57735027,  1.36277029, -1.529843  ,  0.02942065,\n",
       "        -1.6218751 ],\n",
       "       [-0.81649658, -0.57735027,  1.36277029, -1.53976251, -2.76767264,\n",
       "        -1.6372965 ],\n",
       "       [-0.81649658, -0.57735027,  1.36277029, -0.13115188,  1.14497701,\n",
       "        -0.76949991],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  0.92791613, -0.02992062,\n",
       "         0.48303162],\n",
       "       [-0.81649658,  1.73205081, -0.73379939, -0.20932933, -0.2993768 ,\n",
       "        -0.89915412],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -0.17870828,  0.2251352 ,\n",
       "        -1.26401642],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939,  0.1374709 , -0.06929437,\n",
       "         0.50384666],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -1.03967624, -1.05076697,\n",
       "        -0.43852106],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939,  0.09938348, -0.36790317,\n",
       "         0.781818  ],\n",
       "       [-0.81649658, -0.57735027,  1.36277029, -1.21580174,  0.15416247,\n",
       "        -1.34947778],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  1.05822437,  0.97836757,\n",
       "         0.88670051],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939,  0.4401196 ,  0.46754749,\n",
       "         0.40923215],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -0.15151937,  0.62430586,\n",
       "        -0.51983056],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  1.30361149, -0.91073517,\n",
       "         1.30179825],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  0.49781135,  0.83770651,\n",
       "         0.65149135],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -0.92897212, -0.18716957,\n",
       "        -0.23769075],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -1.55149779, -0.24751712,\n",
       "        -1.27140496],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939,  1.96871085,  1.08106713,\n",
       "         1.95818096],\n",
       "       [-0.81649658,  1.73205081, -0.73379939,  0.48063418,  0.15177059,\n",
       "         0.38634632],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -0.59739193, -2.78544219,\n",
       "        -0.04140287],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  0.11649007, -0.93133851,\n",
       "        -0.49867241],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939,  1.36290079,  0.91964899,\n",
       "        -0.60281921],\n",
       "       [-0.81649658,  1.73205081, -0.73379939, -0.08943162, -0.68142339,\n",
       "         0.83126112],\n",
       "       [-0.81649658,  1.73205081, -0.73379939, -0.93093295,  0.14156607,\n",
       "        -0.00821485],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  0.14561902,  1.1736151 ,\n",
       "         0.7905076 ],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  0.31947194,  1.16359793,\n",
       "        -1.6372965 ],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939,  1.11867842, -0.56831342,\n",
       "         0.83298548],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -0.71671353, -1.56095586,\n",
       "        -0.21984184],\n",
       "       [-0.81649658,  1.73205081, -0.73379939, -1.52301833, -0.29261949,\n",
       "         0.76926327],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  1.57413686, -0.18231009,\n",
       "         1.46653355],\n",
       "       [-0.81649658, -0.57735027,  1.36277029,  2.02828029,  0.52173299,\n",
       "         2.18404776],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -1.55149779,  0.46491495,\n",
       "        -1.6372965 ],\n",
       "       [ 1.22474487, -0.57735027, -0.73379939, -1.07135402,  1.21350725,\n",
       "        -1.40779169]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature scalling is performed.\n",
    "\n",
    "#We can also skip this step here as we have only a single feature here. Feature scaling is useful\n",
    "# when we have multiple features, so that they lie on the same scale\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as SC  #we are using standardization\n",
    "sc_X=SC()\n",
    "\n",
    "X_train=sc_X.fit_transform(X_train)\n",
    "X_test=sc_X.fit_transform(X_test)\n",
    "\n",
    "'''''\n",
    "Y_train=sc_X.fit_transform(Y_train)\n",
    "Y_test=sc_X.fit_transform(Y_test)\n",
    "'''''\n",
    "\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Equation will look like this **y = m_1 x_1 +m_2 x_2 + m_3 x_3 + m_4 x_4 + m_5 x_5 + m_6 x_6 + c**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Gradient Descent\n",
    "\n",
    "Now we will use the gradient descent algorithm on this multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b5d3240cc0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#building the model\n",
    "\n",
    "#lets start with a random value of m and c\n",
    "\n",
    "m_1=0\n",
    "m_2=0\n",
    "m_3=0\n",
    "m_4=0\n",
    "m_5=0\n",
    "m_6=0\n",
    "\n",
    "c=0\n",
    "\n",
    "l=0.0001 #l is the learning rate\n",
    "\n",
    "\n",
    "\n",
    "n=float(len(X_train)) # n=number of training data, we are converting it to float since we will need to divide n\n",
    "\n",
    "mse=[]  #we are creating a list for storing mean square errors for each iteration so that we can plot it\n",
    "\n",
    "for i in range (0,20000):\n",
    "    Y_pred=m_1*X_train[:,0:1]+m_2*X_train[:,1:2]+m_3*X_train[:,2:3]+m_4*X_train[:,3:4]+m_5*X_train[:,4:5]+m_6*X_train[:,5:6]+c\n",
    "    \n",
    "    mse.append(numpy.sum((Y_pred-Y_train)**2)/n)\n",
    "    D_m_1= (2/n) * sum(X_train[:,0:1]*(Y_pred-Y_train))\n",
    "    D_m_2= (2/n) * sum(X_train[:,1:2]*(Y_pred-Y_train))\n",
    "    D_m_3= (2/n) * sum(X_train[:,2:3]*(Y_pred-Y_train))\n",
    "    D_m_4= (2/n) * sum(X_train[:,3:4]*(Y_pred-Y_train))\n",
    "    D_m_5= (2/n) * sum(X_train[:,4:5]*(Y_pred-Y_train))\n",
    "    D_m_6= (2/n) * sum(X_train[:,5:6]*(Y_pred-Y_train))\n",
    "    D_c= (2/n) * sum(Y_pred-Y_train)\n",
    "    \n",
    "    #Andrew Ng has not taken 2/n but instead 1/n as his cost function is multiplied by 1/2 to reduce complexity\n",
    "    \n",
    "    m_1=m_1-l*D_m_1\n",
    "    m_2=m_2-l*D_m_2\n",
    "    m_3=m_3-l*D_m_3\n",
    "    m_4=m_4-l*D_m_4\n",
    "    m_5=m_5-l*D_m_5\n",
    "    m_6=m_6-l*D_m_6\n",
    "    c=c-l*D_c\n",
    "   \n",
    " \n",
    "    \n",
    "plt.plot(mse)\n",
    "\n",
    "#see the plot below, we can see the point where MSE stabilises. Run the above loop till that point and take MSE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test=m_1*X_test[:,0:1]+m_2*X_test[:,1:2]+m_3*X_test[:,2:3]+m_4*X_test[:,3:4]+m_5*X_test[:,4:5]+m_6*X_test[:,5:6]+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88402.91449591],\n",
       "       [119289.17187943],\n",
       "       [117553.75703537],\n",
       "       [ 56628.00902773],\n",
       "       [170937.90249187],\n",
       "       [116352.31728574],\n",
       "       [ 56620.46281408],\n",
       "       [ 83967.08233671],\n",
       "       [106927.69975027],\n",
       "       [157747.35711984]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103282.38],\n",
       "       [144259.4 ],\n",
       "       [146121.95],\n",
       "       [ 77798.83],\n",
       "       [191050.39],\n",
       "       [105008.31],\n",
       "       [ 81229.06],\n",
       "       [ 97483.56],\n",
       "       [110352.25],\n",
       "       [166187.94]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
